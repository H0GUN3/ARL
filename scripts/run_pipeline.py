"""
ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸.

ì˜ˆì‹œ:
    python scripts/run_pipeline.py --with-tfdv
"""

from __future__ import annotations

import argparse
from pathlib import Path

from src.data_pipeline import PipelineConfig, run_pipeline


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run BurstGPT data pipeline.")
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("data"),
        help="ì›ë³¸ BurstGPT CSVê°€ ì €ìž¥ëœ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸ê°’: data/)",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("data"),
        help="íŒŒì´í”„ë¼ì¸ ê²°ê³¼ CSVê°€ ì €ìž¥ë  ë””ë ‰í„°ë¦¬ (ê¸°ë³¸ê°’: data/)",
    )
    parser.add_argument(
        "--with-tfdv",
        action="store_true",
        help="TFDV í†µê³„/ìŠ¤í‚¤ë§ˆ/ì´ìƒì¹˜ ë¦¬í¬íŠ¸ë¥¼ artifacts/tfdv/ì— ìƒì„±í•©ë‹ˆë‹¤.",
    )
    parser.add_argument(
        "--min-length",
        type=int,
        default=10_000_000,
        help="validate_timeseriesì— ì‚¬ìš©í•  ìµœì†Œ ê¸¸ì´ ì œì•½ (ê¸°ë³¸ê°’: 10,000,000)",
    )
    parser.add_argument(
        "--no-context-features",
        action="store_true",
        help="ì»¨í…ìŠ¤íŠ¸ íŒŒìƒ í”¼ì²˜(rps_delta_5s ë“±) ì¶”ê°€ë¥¼ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.",
    )
    parser.add_argument(
        "--apply-scaling",
        action="store_true",
        help="Spec ìŠ¤ì¼€ì¼(ê¸°ë³¸: RPS=400~5000, P99=50+0.05*RPS)ë¡œ ë¦¬ìŠ¤ì¼€ì¼í•©ë‹ˆë‹¤.",
    )
    parser.add_argument(
        "--rps-base-offset",
        type=float,
        default=400.0,
        help="ë¦¬ìŠ¤ì¼€ì¼ ì‹œ RPS ê¸°ë³¸ offset (ê¸°ë³¸ê°’: 400)",
    )
    parser.add_argument(
        "--rps-scale",
        type=float,
        default=40.0,
        help="ë¦¬ìŠ¤ì¼€ì¼ ì‹œ ê³±í•´ì§ˆ scale factor (ê¸°ë³¸ê°’: 40)",
    )
    parser.add_argument(
        "--rps-clip",
        type=float,
        default=5_000.0,
        help="ë¦¬ìŠ¤ì¼€ì¼ ì´í›„ RPS ìƒí•œ (ê¸°ë³¸ê°’: 5000)",
    )
    parser.add_argument(
        "--max-latency",
        type=float,
        default=5_000.0,
        help="ë¦¬ìŠ¤ì¼€ì¼ ì´í›„ P99 latency ìƒí•œ (ê¸°ë³¸ê°’: 5000ms)",
    )
    return parser.parse_args()


def build_config(args: argparse.Namespace) -> PipelineConfig:
    artifacts_dir = Path("artifacts/tfdv")
    enable_tfdv = args.with_tfdv
    return PipelineConfig(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        min_length=args.min_length,
        enable_tfdv=enable_tfdv,
        tfdv_stats_path=artifacts_dir / "stats.pbtxt" if enable_tfdv else None,
        tfdv_schema_path=artifacts_dir / "schema.pbtxt" if enable_tfdv else None,
        tfdv_anomalies_path=artifacts_dir / "anomalies.pbtxt" if enable_tfdv else None,
        multi_resolutions=(1.0, 0.1, 0.01),
        add_context_features=not args.no_context_features,
        apply_scaling=args.apply_scaling,
        rps_base_offset=args.rps_base_offset,
        rps_scale=args.rps_scale,
        rps_clip=args.rps_clip,
        max_latency=args.max_latency,
    )


def main() -> None:
    args = parse_args()
    config = build_config(args)
    paths = run_pipeline(config)
    print("âœ… pipeline outputs")
    for name, path in paths.items():
        print(f"  - {name}: {path}")
    if args.with_tfdv:
        print("ðŸ“Š TFDV artifacts saved under artifacts/tfdv/")


if __name__ == "__main__":
    main()
